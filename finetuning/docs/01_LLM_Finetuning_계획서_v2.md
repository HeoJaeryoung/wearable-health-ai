# LLM Fine-tuning 계획서 v2

## 🎯 핵심 컨셉

> **"일관된 전문가 응답 형식과 판단 패턴을 학습시켜 응답 품질을 표준화한다"**

### Fine-tuning으로 학습시키는 것

| 학습 대상         | 설명                | 예시                           |
| ----------------- | ------------------- | ------------------------------ |
| **① 응답 형식**   | 일관된 구조와 포맷  | 마크다운 표, 섹션 구조, 이모지 |
| **② 판단 패턴**   | 입력 → 판단 규칙    | "RHR +10bpm → 휴식 권장"       |
| **③ 인용 스타일** | 전문 근거 언급 방식 | "(Buchheit, 2014)" 형식        |
| **④ 톤/페르소나** | 친근한 전문가 말투  | "~해요", "~드려요"             |

### Fine-tuning으로 학습시키지 않는 것

| 항목           | 이유                      | 대안           |
| -------------- | ------------------------- | -------------- |
| 전문 지식 자체 | 비효율적, 업데이트 어려움 | RAG로 처리     |
| 실시간 데이터  | 학습 불가                 | API로 주입     |
| 복잡한 계산    | LLM 부적합                | 규칙 기반 코드 |

---

## 📋 학습 대상 정의

### 1. 9가지 생체 데이터 판단 패턴

| 지표                 | 판단 기준        | 학습할 패턴                                   |
| -------------------- | ---------------- | --------------------------------------------- |
| `resting_heart_rate` | 평소 대비 변화량 | +5 이내 → 정상 / +10 이상 → 휴식 권장         |
| `sleep_hr`           | 절대값           | 7시간+ → 충분 / 6시간- → 부족 / 5시간- → 경고 |
| `steps`              | 절대값           | 7000+ → 양호 / 5000- → 부족                   |
| `heart_rate`         | 범위             | 60-100 → 정상                                 |
| `oxygen_saturation`  | 절대값           | 95%+ → 정상 / 93%- → 주의                     |
| `active_calories`    | 절대값           | 300+ → 양호                                   |
| `distance_km`        | 절대값           | 5km+ → 양호                                   |
| `bmi`                | 범위             | 18.5-24.9 → 정상                              |
| `weight`             | 참조용           | 단독 판단 없음                                |

### 2. 17가지 시드 운동 분석 패턴

| 운동 유형 | 판단 기준        | 학습할 패턴      |
| --------- | ---------------- | ---------------- |
| 유산소    | 목표 심박수 범위 | 카보넨 공식 언급 |
| 근력      | 세트/반복 적정성 | ACSM 권장량 언급 |
| 스트레칭  | 지속 시간        | 동적/정적 구분   |

### 3. 컨디션 → 운동 강도 매핑 패턴 (6등급)

| 컨디션 점수 | 등급 |  레이블   | 운동 권장                  |
| :---------: | :--: | :-------: | -------------------------- |
|   80-100    |  A   | 매우 우수 | 고강도 포함 모든 운동 가능 |
|    70-79    |  B   |   우수    | 중-고강도 가능             |
|    55-69    |  C+  | 보통 이상 | 중강도까지 권장            |
|    45-54    |  C   |   보통    | 중강도까지 권장            |
|    35-44    |  D   | 개선 필요 | 저강도만 권장              |
|    0-34     |  F   | 주의 필요 | 휴식 권장                  |

---

## 📝 응답 형식 표준화

### 건강 분석 응답 형식 (간소화)

```markdown
## [등급 이모지] 컨디션: [등급명] ([점수]/100)

**판단 근거:**

- 수면 X시간 → [판정]
- 안정시 심박 Xbpm (평소 대비 +X) → [판정]
- 활동량 X보 → [판정]

💡 **오늘의 권장:** [권장 강도]

📚 참고: [관련 연구/기준]
```

### 운동 분석 응답 형식 (간소화)

```markdown
## 🏋️ 루틴 분석: [적합/부적합]

**컨디션:** [등급] ([점수]/100) → [권장 강도]

**목표 심박수:** X-Xbpm ([강도])
└ 카보넨 공식: (220-나이-RHR) × X%-X% + RHR

**루틴:** X분 (운동 목록)

💡 **코멘트:** [핵심 조언]

⚠️ **주의:** [해당 시 주의사항]
```

### 챗봇 응답 형식

```markdown
[핵심 답변 1-2문장]

💡 [실천 가능한 조언 1문장]

📚 (해당 시) 참고: [연구명]
```

---

## 📊 학습 데이터 구성

### 데이터 분할

| 구분     |    건수     | 비율 | 용도                         |
| -------- | :---------: | :--: | ---------------------------- |
| Train    |   1,200건   | 80%  | Azure Fine-tuning 학습       |
| Valid    |    150건    | 10%  | 학습 중 검증 (Loss 모니터링) |
| Test     |    150건    | 10%  | 학습 후 모델 평가            |
| **총계** | **1,500건** | 100% |                              |

### 카테고리별 분포

| 카테고리      | 건수  | 비율 | 목적                         |
| ------------- | :---: | :--: | ---------------------------- |
| 건강 분석     | 400건 | 27%  | 생체 데이터 → 건강 상태 해석 |
| 운동 분석     | 300건 | 20%  | 루틴 적합도 + 카보넨 공식    |
| 코칭 챗봇     | 500건 | 33%  | 건강/운동 관련 Q&A           |
| **판단 패턴** | 300건 | 20%  | 명시적 판단 근거 학습 (신규) |

### v1 → v2 변경 사항

| 항목                |   v1   |      v2      |
| ------------------- | :----: | :----------: |
| 건강 분석 응답 길이 | ~500자 |  **~200자**  |
| 운동 분석 응답 길이 | ~600자 |  **~250자**  |
| 챗봇 응답 길이      | ~300자 |  **~150자**  |
| 판단 근거           | 암묵적 |  **명시적**  |
| 데이터 분할         | 80:20  | **80:10:10** |

---

## 🔄 판단 패턴 명세

### 패턴 1: 수면 부족 판단

```
입력: sleep_hr < 6
출력:
- 판정: "⚠️ 수면 부족"
- 권장: "고강도 운동 피하기"
- 인용: "(Milewski et al., 2014)"
```

### 패턴 2: RHR 상승 판단

```
입력: resting_heart_rate - usual_resting_heart_rate >= 10
출력:
- 판정: "🚨 피로 신호"
- 권장: "휴식 또는 저강도만"
- 인용: "(Buchheit, 2014)"
```

### 패턴 3: 복합 판단

```
입력: sleep_hr < 5 AND rhr_change >= 10
출력:
- 판정: "🚨 경고"
- 권장: "오늘은 반드시 휴식"
- 인용: 두 연구 모두 언급
```

---

## 📈 평가 체계

### 두 가지 평가

| 구분       | 모델 평가                   | 서비스 평가                  |
| ---------- | --------------------------- | ---------------------------- |
| **데이터** | test*model*\*.jsonl (150건) | evaluation/datasets/ (100건) |
| **형식**   | Train/Valid와 동일          | 다름 (JSON 객체)             |
| **목적**   | 모델 학습 품질 측정         | 3단계 출력 비교              |
| **지표**   | 정답(assistant) 일치율      | 키워드, 인용율, 톤 등        |

### 서비스 평가 지표

| 지표                   | 측정 방법              | Baseline 예상 | Fine-tuned 목표 |
| ---------------------- | ---------------------- | :-----------: | :-------------: |
| **응답 구조 일치율**   | 필수 섹션 포함 여부    |      60%      |    **95%+**     |
| **컨디션 등급 정확도** | 입력 → 올바른 등급     |      70%      |    **95%+**     |
| **전문 기준 인용율**   | Buchheit/Milewski 인용 |      20%      |    **80%+**     |
| **응답 길이 적절성**   | 목표 범위 내           |      50%      |    **85%+**     |

---

## 📁 파일 구조

```
finetuning_v2/
├── scripts/
│   ├── 01_health_interpretation_generator_v2.py   # 건강 분석 (400건)
│   ├── 02_exercise_analysis_generator_v2.py       # 운동 분석 (300건)
│   ├── 03_coaching_chat_generator_v2.py           # 코칭 챗봇 (500건)
│   ├── 04_decision_pattern_generator.py           # 판단 패턴 (300건) ★신규
│   └── 05_merge_and_split.py                      # 통합 및 분할
├── data/
│   ├── train_YYYYMMDD.jsonl                       # 학습 (1,200건)
│   ├── valid_YYYYMMDD.jsonl                       # 검증 (150건)
│   └── test_model_YYYYMMDD.jsonl                  # 모델 평가 (150건)
└── docs/
    ├── 01_LLM_Finetuning_계획서.md
    ├── 02_전문기준_정리.md
    └── 03_README.md
```

---

## 📅 실행 계획

| 단계 | 작업                            |  상태   |
| :--: | ------------------------------- | :-----: |
|  1   | 학습 데이터 생성 코드 v2 작성   | ✅ 완료 |
|  2   | 학습 데이터 1,500건 생성        |  대기   |
|  3   | Azure Fine-tuning 실행          |  대기   |
|  4   | 모델 평가 (test*model*\*.jsonl) |  대기   |
|  5   | 서비스 평가 (3단계 비교)        |  대기   |
|  6   | 결과 분석 및 문서화             |  대기   |

---

## ⚙️ Azure Fine-tuning 설정

| 파라미터      |        권장값         |
| ------------- | :-------------------: |
| Base Model    | Llama 3.1 8B Instruct |
| Epochs        |           3           |
| Batch Size    |           4           |
| Learning Rate |         2e-4          |
| LoRA Rank     |          16           |
| LoRA Alpha    |          32           |

---

## 💡 핵심 요약

**Fine-tuning의 목적:**

- ❌ 전문 지식을 모델에 주입하는 것
- ✅ **일관된 응답 형식과 판단 패턴을 학습시켜 품질을 표준화하는 것**

**학습 데이터 설계 원칙:**

1. 응답은 **짧고 일관되게**
2. 판단 근거를 **명시적으로**
3. 형식을 **통일**
4. 전문 인용은 **패턴화**
