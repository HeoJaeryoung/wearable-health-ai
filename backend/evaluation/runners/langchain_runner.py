"""
LangChain í‰ê°€ ì‹¤í–‰ê¸° v2
- ì‹¤í–‰: python -m evaluation.runners.langchain_runner
- íŒŒì¼ì €ì¥: evaluation/results/langchain/

- 1,2,3ë‹¨ê³„ ê²°ê³¼ ë¹„êµ: python -m evaluation.runners.chat_compare_runner
- íŒŒì¼ì €ì¥: evaluation/results/compare/

BaselineRunnerë¥¼ ìƒì†ë°›ì•„ ìŠ¤í…Œì´ì§€ëª…ê³¼ ì €ì¥ ê²½ë¡œë§Œ ë³€ê²½
ë™ì¼í•œ í…ŒìŠ¤íŠ¸ì…‹, ë™ì¼í•œ ë©”íŠ¸ë¦­ìœ¼ë¡œ ë¹„êµ í‰ê°€
"""

from pathlib import Path
from datetime import datetime
import json
import os

from evaluation.runners.baseline_runner import BaselineRunner
from evaluation.config import RESULTS_DIR


class LangchainRunner(BaselineRunner):
    """LangChain í‰ê°€ ëŸ¬ë„ˆ v2"""

    def __init__(self):
        super().__init__()  # ë¶€ëª¨ ì´ˆê¸°í™” ë¨¼ì €

        # ë¶€ëª¨ ì´ˆê¸°í™” í›„ EVAL_MODE ë®ì–´ì“°ê¸°
        os.environ["EVAL_MODE"] = "langchain"
        print("[INFO] EVAL_MODE = langchain (override)")

        self.stage = "langchain"

    def _generate_summary(self) -> dict:
        """ìš”ì•½ í†µê³„ ìƒì„± (ìŠ¤í…Œì´ì§€ëª… ë³€ê²½)"""
        summary = super()._generate_summary()
        summary["stage"] = self.stage
        return summary

    def save_results(self, output_dir: str = None) -> Path:
        """ê²°ê³¼ ì €ì¥ (langchain ê²½ë¡œ)"""
        if output_dir is None:
            output_dir = f"{RESULTS_DIR}/langchain"

        Path(output_dir).mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = Path(output_dir) / f"results_{timestamp}.json"

        output_data = {
            "metadata": {
                "stage": self.stage,
                "version": "v2.1",
                "timestamp": datetime.now().isoformat(),
                "api_base_url": self.base_url,
                "description": "LangChain Chain + Structured Output ì ìš© ë²„ì „",
                "improvements": [
                    "LangChain ChatPromptTemplate ì‚¬ìš©",
                    "with_structured_output() ì ìš©",
                    "Pipeline (prompt | llm) êµ¬ì„±",
                    "Few-shot Prompting ì¶”ê°€",
                ],
                "condition_grades": "6ë“±ê¸‰ (A/B/C+/C/D/F)",
            },
            "summary": self.summary,
            "results": self.results,
        }

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        return output_path

    def print_summary(self):
        """ìš”ì•½ ì¶œë ¥ (í—¤ë” ë³€ê²½)"""
        print("\n" + "=" * 60)
        print("ğŸ“Š LangChain í‰ê°€ ìš”ì•½ ")
        print("=" * 60)

        print(f"\nì´ í…ŒìŠ¤íŠ¸: {self.summary.get('total_queries', 0)}ê±´")

        for service, stats in self.summary.get("by_service", {}).items():
            service_name = {
                "health": "ê±´ê°• ë¶„ì„",
                "exercise": "ìš´ë™ ë¶„ì„",
                "chat": "ì±—ë´‡",
            }.get(service, service)

            print(f"\n[{service_name}] ({stats['count']}ê±´)")
            print(f"   ì •í™•ë„: {stats['avg_accuracy']:.1f}%")
            print(f"   í‚¤ì›Œë“œ ë§¤ì¹­: {stats['avg_keyword_match']:.2f}")
            print(f"   ì¼ê´€ì„±: {stats['avg_consistency']:.2f}")
            print(f"   ì‘ë‹µ ì‹œê°„: {stats['avg_time']:.2f}ì´ˆ")

            # v2 ì§€í‘œ
            print(f"   [v2 ì§€í‘œ]")
            print(f"   ì‘ë‹µ êµ¬ì¡° ì ìˆ˜: {stats['avg_structure_score']:.1f}%")
            print(f"   ì¸ìš© ì ìˆ˜: {stats['avg_citation_strict_score']:.1f}%")
            print(f"   ê°œë… ì ìš© ì ìˆ˜: {stats['avg_concept_score']:.1f}%")
            print(f"   ê¸¸ì´ ì ì ˆì„±: {stats['avg_length_score']:.1f}%")

            if "grade_accuracy" in stats:
                print(f"   ë“±ê¸‰ ì •í™•ë„: {stats['grade_accuracy']:.1f}%")
            if "karvonen_citation_rate" in stats:
                print(f"   ì¹´ë³´ë„¨ ì¸ìš©ìœ¨: {stats['karvonen_citation_rate']:.1f}%")

        if "overall" in self.summary:
            print(f"\n[ì „ì²´ í‰ê· ]")
            print(f"   ì •í™•ë„: {self.summary['overall']['avg_accuracy']:.1f}%")
            print(f"   ì‘ë‹µ ì‹œê°„: {self.summary['overall']['avg_time']:.2f}ì´ˆ")
            print(
                f"   ì‘ë‹µ êµ¬ì¡° ì ìˆ˜: {self.summary['overall']['avg_structure_score']:.1f}%"
            )


if __name__ == "__main__":
    runner = LangchainRunner()
    runner.run_all()
    runner.print_summary()
    runner.save_results()
